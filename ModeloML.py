# -*- coding: utf-8 -*-
"""LP4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YgXNiW_X8c9OVFLTP4o3-GM2ah0JtjFo
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from tpot import TPOTClassifier
from sklearn.metrics import accuracy_score
from sklearn.tree import export_graphviz
import graphviz
import numpy as np
import seaborn as sns
import country_converter as coco
import pycountry_convert as pycoco

def KMeansOtimization(num_clusters, classe):
  model = KMeans(n_clusters = num_clusters)
  model.fit(classe)
  return [num_clusters, model.inertia_]

data = pd.read_csv('/content/drive/My Drive/LP4/data-final.csv', sep = "\t", nrows = 100000)
#data_final = data_final.head(10000)

data.dropna(inplace=True)

iso2 = list(data["country"].unique())

unknown_iso2 = ["NONE", "SX", "TL", "AQ"]

iso3 = coco.convert(names = iso2, to = "ISO3")
continent = pd.Series(iso2)[~pd.Series(iso2).isin(unknown_iso2)]
list_continent=[]
for i in continent:
  list_continent.append(pycoco.country_alpha2_to_continent_code(i))
continent = pd.Series(list_continent)
short_name = coco.convert(names = iso2, to = "name_short")
continent = pd.Series(list_continent)
dict_continent_name = {
    'NA': 1, #'North America'
    'SA': 2,#'South America', 
    'AS': 3,#'Asia',
    'OC': 4,#'Oceania',
    'EU': 5,#'Europe',
    'AF': 6 #'Africa'
}

continent = continent.replace(dict_continent_name)
dict_country = dict(zip(iso2, iso3))
dict_short_name = dict(zip(iso3, short_name))
dict_continent = dict(zip(iso2, continent))

data["country_iso2"] = data["country"].replace(dict_country)
data["country_iso3"] = data["country"].replace(dict_country)
data["country_name"] = data["country_iso3"].replace(dict_short_name)
data["continent"] = data["country"].replace(dict_continent)

frequency = pd.DataFrame(data['country_name'].value_counts())
frequency.reset_index(inplace=True)
frequency.columns = ['country_name', 'Frequencia']
frequency = frequency.query("Frequencia > 1000")
data = data[data['country_name'].isin(frequency['country_name'])]
data = data.query("country_name != 'not found'")
#x = data[['EXT1',	'EXT2',	'EXT3',	'EXT4',	'EXT5',	'EXT6',	'EXT7',	'EXT8',	'EXT9',	'EXT10',	'EST1',	'EST2',	'EST3',	'EST4',	'EST5',	'EST6',	'EST7',	'EST8',	'EST9',	'EST10',	'AGR1',	'AGR2',	'AGR3',	'AGR4',	'AGR5',	'AGR6',	'AGR7',	'AGR8',	'AGR9',	'AGR10',	'CSN1',	'CSN2',	'CSN3',	'CSN4',	'CSN5',	'CSN6',	'CSN7',	'CSN8',	'CSN9',	'CSN10','OPN1','OPN2','OPN3','OPN4','OPN5','OPN6','OPN7','OPN8','OPN9','OPN10']]

x = data[['EXT1',	'EST1',	'AGR1',	'CSN1',	'OPN1',	'EXT2',	'EST2',	'AGR2',	'CSN2',	'OPN2']]
y = data['country_name']
list_classes = y.unique()

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.cluster import AgglomerativeClustering

#scaler = StandardScaler()
#scaled_x = scaler.fit_transform(x)
#scaled_x = pd.DataFrame(scaled_x, columns=x.columns)
scaled_x = x

#result = [KMeansOtimization(clusters,scaled_x) for clusters in range(1, 20)]

#result = pd.DataFrame(result,columns=['Cluster', 'Erro'])

#result['Erro'].plot(xticks =result['Cluster'])

kmeans = KMeans(n_clusters=5)
kmeans.fit(scaled_x)
groups = pd.DataFrame(kmeans.cluster_centers_, columns = scaled_x.columns)
groups = groups.transpose()
groups.plot.bar(subplots = True, figsize = (30, 20), sharex =False ,rot = 0 )

scaled_x['continent'] = data['continent']
scaled_x['Cluster'] =kmeans.labels_

scaled_x.dropna(inplace=True)
y = y.loc[scaled_x.index]
print(y.shape)
print(scaled_x.shape)

from scipy.cluster.hierarchy import dendrogram, linkage

matriz_de_distancia = linkage(groups)
dendrogram(matriz_de_distancia)

from sklearn.manifold import TSNE
tsne = TSNE()

#visualizacao = tsne.fit_transform(scaled_x)
#visualizacao

#sns.set(rc={'figure.figsize': (13, 13)})
#sns.scatterplot(x = visualizacao[:,0], y = visualizacao[:,1], hue =kmeans.labels_, palette=sns.color_palette('Set1', 4) )

#x['continent'] = pd.to_numeric(x['continent'])
scaled_x.info()

corr = scaled_x.corr()

mask = np.triu(np.ones_like(corr, dtype=np.bool))
  f, ax = plt.subplots(figsize=(15, 13))
  cmap = sns.diverging_palette(240, 10, as_cmap=True)
  sns.heatmap(corr, mask=mask, cmap=cmap, center=0,
                square=True, linewidths=.5, cbar_kws={"shrink": .5})

#raw_treino_x, raw_teste_x, treino_y, teste_y = train_test_split(x, y,
#                                                         test_size = 0.25,
#                                                         stratify = y)
#
#print("Treinaremos com %d elementos e testaremos com %d elementos" % (len(raw_treino_x), len(raw_teste_x)))
#
#modelo = TPOTClassifier(verbosity = 2, generations=5, n_jobs=-1, config_dict="TPOT light")
#modelo.fit(raw_treino_x, treino_y)

raw_treino_x, raw_teste_x, treino_y, teste_y = train_test_split(scaled_x, y,
                                                         test_size = 0.25,
                                                         stratify = y)

print("Treinaremos com %d elementos e testaremos com %d elementos" % (len(raw_treino_x), len(raw_teste_x)))

modelo = DecisionTreeClassifier(max_depth=6)
modelo.fit(raw_treino_x, treino_y)
previsoes_SVC = modelo.predict(raw_teste_x)
acuracia = accuracy_score(teste_y, previsoes_SVC) * 100
print("A acurácia foi %.2f%%" % acuracia)

    
dot_data = export_graphviz(modelo, out_file=None,  feature_names = scaled_x.columns, filled=True, rounded=True, class_names=list_classes )
grafico = graphviz.Source(dot_data)


pred = modelo.predict([[5,5,5,5,1,1,1,1,1,5,5, 1]])
print("Previsão: "+ pred[0])

centr = kmeans.predict([[1,1,1,1,1,1,1,1,1,1]])
print("Centroide: "+ str(centr[0]))

